{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e805d4f6-7d3f-4e18-a38f-75ae32455e71",
   "metadata": {},
   "source": [
    "\n",
    "# Observer\n",
    "\n",
    "This Observer notebook monitors USB cameras for changes on the DMA playing field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12503c2c-c4f8-4484-a10b-cdccccf1cfea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "from matplotlib import pyplot as plt\n",
    "from pyzbar.pyzbar import decode\n",
    "from math import cos, degrees, radians\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "\n",
    "from dataclasses import dataclass\n",
    "# %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f815113c-9ecd-4483-903e-767a06152342",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CamCoordinate:\n",
    "    x: int\n",
    "    y: int\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class RealCoordinate:\n",
    "    x: float\n",
    "    y: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae0fc0e2-68b4-445c-a132-c3d033ceeb8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "sr.readModel(\"FSRCNN_x4.pb\")\n",
    "sr.setModel(\"fsrcnn\", 4);\n",
    "\n",
    "\n",
    "def capture_camera(cam_num):\n",
    "    try:\n",
    "        cam = cv2.VideoCapture(cam_num)\n",
    "        retval, image = cam.read()\n",
    "    finally:\n",
    "        cam.release()\n",
    "    retval, buff = cv2.imencode('.jpg', image)\n",
    "    return buff\n",
    "\n",
    "\n",
    "MAX_CAM_ID = 10\n",
    "\n",
    "\n",
    "def identify_usb_cameras(device_numbers=list(range(MAX_CAM_ID))):\n",
    "    functional = []\n",
    "    for dn in device_numbers:\n",
    "        try:\n",
    "            img = capture_camera(dn)\n",
    "            functional.append(dn)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    return functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8017224-ca09-4668-9e92-3704e9246435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CalibrationBox:\n",
    "    observedCorners: list[tuple]\n",
    "    observedRect: list\n",
    "    orientation: str\n",
    "    realCoordinate: tuple\n",
    "    \n",
    "    millimetersPerPixel = 5\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        # if oC[1] changes  oC[0]'s y more than it's x, rotate point order\n",
    "        # This tries to normalize the point order from the QR code so the image can be properly rotated\n",
    "        oC0, oC1 = self.observedCorners[:2]\n",
    "        if abs(oC1[0] - oC0[0]) > abs(oC1[1] - oC0[1]):\n",
    "            self.observedCorners = [self.observedCorners[-1], *self.observedCorners[:-1]]\n",
    "        \n",
    "        acceptedOrientations = ['UP', 'LEFT', 'DOWN', 'RIGHT']\n",
    "        assert self.orientation in acceptedOrientations, f\"Unrecognized orientation: {orientation}\"\n",
    "        orientationIdx = acceptedOrientations.index(self.orientation)\n",
    "        self.observedCorners = np.float32(self.observedCorners)\n",
    "        self.cornerOrder = [[0, 1, 2, 3], [3, 0, 1, 2], [2, 3, 0, 1], [1, 2, 3, 0]][orientationIdx]\n",
    "    \n",
    "    @property\n",
    "    def midpoint(self):\n",
    "        x, y, w, h = self.observedRect\n",
    "        return x + w/2, y + h/2\n",
    "\n",
    "    @property\n",
    "    def unwarpedCorners(self):\n",
    "        mpx, mpy = self.realCoordinate\n",
    "        wMod, hMod = 5, 5\n",
    "        cornerModifiers = [(mpx - wMod, mpy - hMod), (mpx - wMod, mpy + hMod), (mpx + wMod, mpy + hMod), (mpx + wMod, mpy - hMod)]\n",
    "        orderedModifiers = [cornerModifiers[idx] for idx in self.cornerOrder]\n",
    "        return np.float32(orderedModifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "213cb2d2-24c4-40a6-981e-9cc14e4238ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Camera:\n",
    "    camNum: int\n",
    "    activeZone: list\n",
    "    \n",
    "    IMAGE_BUFFER_DEPTH = 2\n",
    "    CAPTURE_FRAMES = 3\n",
    "    xmax = 2560\n",
    "    ymax = 1920\n",
    "    \n",
    "    @property\n",
    "    def mostRecentFrame(self):\n",
    "        return self.imageBuffer[0]\n",
    "    \n",
    "    def setActiveZone(self, newAZ):\n",
    "        self.activeZone = np.float32(newAZ)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.imageBuffer = [None for i in range(self.IMAGE_BUFFER_DEPTH)]\n",
    "        self.imageDeltas = [None for i in range(self.IMAGE_BUFFER_DEPTH)]\n",
    "        self.setActiveZone(self.activeZone)\n",
    "        self.M = None\n",
    "        self.MCalibratedTo = None\n",
    "        self.minimumWidth = 100\n",
    "    \n",
    "    def process(self, image):\n",
    "        M = self.M\n",
    "        activeZone = self.drawActiveZone(image)\n",
    "        activeZone = cv2.circle(activeZone, [425, 450], radius=3, thickness=2, color=(255,0,255))\n",
    "        d1 = cv2.circle(activeZone, [515, 325], radius=3, thickness=2, color=(0,255,255))\n",
    "        dst = cv2.flip(cv2.warpPerspective(d1, M, (self.xmax, self.ymax)), 0)\n",
    "        x = np.zeros((image.shape[0],10,3), np.uint8)\n",
    "        result = np.hstack((activeZone, x, dst))\n",
    "        return dst\n",
    "    \n",
    "    def pointInActiveZone(self, p):\n",
    "        return cv2.pointPolygonTest(self.activeZone, p, False) >= 0\n",
    "    \n",
    "    def tuneToCalibrationBox(self, calibrationBox: CalibrationBox):\n",
    "        self.M = cv2.getPerspectiveTransform(calibrationBox.observedCorners, calibrationBox.unwarpedCorners)\n",
    "        self.MCalibratedTo = calibrationBox.realCoordinate\n",
    "    \n",
    "    def calibrate(self, realBoxMidpoint=(0, 0)):\n",
    "        rx, ry = realBoxMidpoint\n",
    "        try:\n",
    "            decoded = decode(self.mostRecentFrame)[0]\n",
    "        except IndexError:\n",
    "            raise Exception(f\"Failed to locate QR Calibration Box on Camera {self.camNum}\")\n",
    "        self.tuneToCalibrationBox(CalibrationBox(decoded.polygon, decoded.rect, decoded.orientation, realBoxMidpoint))\n",
    "\n",
    "    def convertCameraToRealSpace(self, p):\n",
    "        assert not (self.M is None), \"Must calibrate camera before converting coordinates\"\n",
    "        M = self.M\n",
    "        px = (M[0][0]*p[0] + M[0][1]*p[1] + M[0][2]) / ((M[2][0]*p[0] + M[2][1]*p[1] + M[2][2]))\n",
    "        py = (M[1][0]*p[0] + M[1][1]*p[1] + M[1][2]) / ((M[2][0]*p[0] + M[2][1]*p[1] + M[2][2]))\n",
    "        return (px, py)\n",
    "    \n",
    "    @staticmethod\n",
    "    def distanceFormula(pt0, pt1):\n",
    "        return sum([(b - a)**2 for a, b in zip(pt0, pt1)]) ** 0.5\n",
    "    \n",
    "    def cameraPointsToRealDistance(self, pt0, pt1):\n",
    "        \"\"\" Calculates distance between cam's RealSpace coordinates to distance in mm \"\"\"\n",
    "        ptr0 = cam0.convertCameraToRealSpace(pt0)\n",
    "        ptr1 = cam0.convertCameraToRealSpace(pt1)\n",
    "        return self.distanceFormula(ptr0, ptr1) * CalibrationBox.millimetersPerPixel\n",
    "        \n",
    "    def showUnwarpedImage(self):\n",
    "        warp = cv2.warpPerspective(self.cropToActiveZone(self.imageBuffer[0]), self.M, (1000, 1000))\n",
    "        f, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "        ax.imshow(warp)\n",
    "        plt.show()\n",
    "        return warp\n",
    "\n",
    "    def collectImage(self, delay=0.1):\n",
    "        cap = cv2.VideoCapture(self.camNum)\n",
    "        sleep(delay)\n",
    "        image = None\n",
    "        try:\n",
    "            for frame in range(self.CAPTURE_FRAMES):\n",
    "                ret, cv2_im = cap.read()\n",
    "                sleep(delay)\n",
    "            image = sr.upsample(cv2_im)\n",
    "            self.imageBuffer.insert(0, image)\n",
    "            self.imageBuffer.pop()\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to capture Camera: {e}\")\n",
    "        finally:\n",
    "            cap.release()\n",
    "        return image\n",
    "    \n",
    "    @staticmethod\n",
    "    def boxToBasePoint(box):\n",
    "        x, y, w, h = box\n",
    "        return (int(x + w / 2), int(y + h * 0.75))\n",
    "    \n",
    "    def changeBetween(self, im0, im1):\n",
    "        if im0 is None or im1 is None:\n",
    "            return []\n",
    "        img_height = im0.shape[0]\n",
    "        diff = cv2.absdiff(cv2.cvtColor(im0, cv2.COLOR_BGR2GRAY),\n",
    "                           cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY))\n",
    "        thresh = cv2.threshold(diff,64,255,cv2.THRESH_BINARY)[1]\n",
    "        kernel = np.ones((5,5), np.uint8) \n",
    "        dilate = cv2.dilate(thresh, kernel, iterations=2)\n",
    "        contours = cv2.findContours(dilate.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = imutils.grab_contours(contours)\n",
    "        boxes = []\n",
    "        for contour in contours:\n",
    "            bRect = cv2.boundingRect(contour)\n",
    "            x, y, w, h = bRect\n",
    "            area = w * h\n",
    "            presumedBasePoint = self.boxToBasePoint((x, y, w, h))\n",
    "            if 10000000 > area > 10000 and self.pointInActiveZone(presumedBasePoint):\n",
    "                boxes.append(cv2.boundingRect(contour))\n",
    "        return boxes\n",
    "    \n",
    "    def captureTransition(self, box):\n",
    "        x, y, w, h = box\n",
    "        before = self.imageBuffer[1][y:y+h, x:x+w]\n",
    "        after = self.imageBuffer[0][y:y+h, x:x+w]\n",
    "        return before, after\n",
    "    \n",
    "    def capture(self):\n",
    "        newImage = self.collectImage()\n",
    "        delta = self.changeBetween(self.imageBuffer[1], newImage)\n",
    "        self.imageDeltas.insert(0, delta)\n",
    "        self.imageDeltas.pop()\n",
    "        transitions = [self.captureTransition(d) for d  in delta]\n",
    "        return newImage, delta, transitions\n",
    "    \n",
    "    def cropToActiveZone(self, image):\n",
    "        pts = np.int32(self.activeZone)\n",
    "        mask = np.zeros(image.shape[:2], np.uint8)\n",
    "        cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "        dst = cv2.bitwise_and(image, image, mask=mask)\n",
    "        return dst\n",
    "        \n",
    "    def drawActiveZone(self, image):\n",
    "        pts = np.int32(self.activeZone)\n",
    "        azOverlaidImage = image.copy()\n",
    "        return cv2.polylines(azOverlaidImage, [pts], isClosed=True, color=(255,0,0), thickness=5)\n",
    "\n",
    "    @classmethod\n",
    "    def drawBoxesOnImage(cls, image, boxes):\n",
    "        imageWithBoxes = image.copy()\n",
    "        for x, y, w, h in boxes:\n",
    "            cv2.rectangle(imageWithBoxes, (x, y), (x+w, y+h), (0,0,255), 2)\n",
    "            presumedBasePoint = cls.boxToBasePoint((x, y, w, h))\n",
    "            cv2.circle(imageWithBoxes, presumedBasePoint, radius=4, thickness=4, color=(0,255,255))\n",
    "            cv2.putText(imageWithBoxes, f'{x}-{x+w}, {y}-{y+w}', (x, y), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        return imageWithBoxes\n",
    "\n",
    "    def showTransition(self, i0, i1):\n",
    "        changes = self.changeBetween(i0, i1)\n",
    "        return np.hstack((\n",
    "            self.drawBoxesOnImage(i0, changes),\n",
    "            np.zeros((i0.shape[0], 10, 3), np.uint8),\n",
    "            self.drawBoxesOnImage(i1, changes)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def swapBox(srcIm, dstIm, box):\n",
    "        swapped = dstIm.copy()\n",
    "        x, y, w, h = box\n",
    "        orig = srcIm[y:y+h, x:x+w]\n",
    "        swapped[y:y+h, x:x+w] = orig\n",
    "        return swapped\n",
    "        \n",
    "    def showActiveZone(self):\n",
    "        print(self.activeZone)\n",
    "        self.capture()\n",
    "        plt.imshow(self.drawActiveZone(self.mostRecentFrame))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf55c5cc-19e3-460d-a33e-f00508e1963c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CaptureObject:\n",
    "    name: str\n",
    "    camBoxes: {int: list[int]}\n",
    "    \n",
    "    def camCoordinateMatch(self, coords: {int: CamCoordinate}, wiggle=80) -> bool:\n",
    "        for camNum, coord in coords.items():\n",
    "            x, y = coord.x, coord.y\n",
    "            for camBox in self.camBoxes[camNum]:\n",
    "                capX, capY, _, _ = camBox\n",
    "                if x - wiggle < capX < x + wiggle and y - wiggle < capY < y + wiggle:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    def update(self, camBoxes):\n",
    "        self.camBoxes = camBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaee4731-e369-4dfe-ab10-ea7541881908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CaptureConfiguration:\n",
    "    name: str\n",
    "    captureObjects: {str: CaptureObject} = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.roundCounter = 0\n",
    "        self.captureObjects = {} if self.captureObjects is None else self.captureObjects\n",
    "        self.lastCapture = None\n",
    "    \n",
    "    def capture(self):\n",
    "        self.lastCapture = {cam.camNum: cam.capture() for cam in cameras.values()}\n",
    "        return self.lastCapture\n",
    "        \n",
    "    def defineObject(self, name: str, captures):\n",
    "        camBoxes = {camNum: capture[1] for camNum, capture in captures.items()}\n",
    "        self.captureObjects[name] = CaptureObject(name, camBoxes)\n",
    "    \n",
    "    def updateObject(self, name: str, camBoxes: {int: list[int]}, transition: {int: list[np.ndarray]}):\n",
    "        self.captureObjects[name].update(camBoxes)\n",
    "\n",
    "    def identifySelectedObject(self, captures):\n",
    "        camCaptures = {cN: [d for d in cap[1]] for cN, cap in captures.items()}\n",
    "        for capObj in self.captureObjects.values():\n",
    "            originMatches = {cN: [] for cN in cameras}\n",
    "            transition = {cN: [None, None] for cN in cameras}\n",
    "            for camNum, (newImage, changeBoxes, transitions) in captures.items():\n",
    "                for bid, box in enumerate(changeBoxes):\n",
    "                    if capObj.camCoordinateMatch({camNum: CamCoordinate(*box[:2])}):\n",
    "                        originMatches[camNum].append(box)\n",
    "                        transition[camNum][0] = transitions[bid]\n",
    "            if sum([len(capObj.camBoxes[cN]) == len(originMatches[cN]) for cN in cameras]) == len(cameras):\n",
    "                return capObj, originMatches, transition\n",
    "        raise Exception(\"Unable to Identify Object to Update\")\n",
    "    \n",
    "    def scanCamsForCalibrationBoxes(self):\n",
    "        return {cam.camNum: (qrs := decode(cam.mostRecentFrame), len(qrs)) for cam in cameras.values()}\n",
    "    \n",
    "    def objectsByBoxOrigin(self, coord: CamCoordinate):\n",
    "        objs = []\n",
    "        for objName, obj in self.captureObjects.items():\n",
    "            if obj.camCoordinateMatch(coord):\n",
    "                objs.append(obj)\n",
    "        return objs\n",
    "    \n",
    "    def drawObjectsOnCam(self, cam, image=None):\n",
    "        img = (cam.imageBuffer[0] if image is None else image).copy()\n",
    "        for obj in self.captureObjects.values():\n",
    "            if cam.camNum in obj.camBoxes:\n",
    "                img = cam.drawBoxesOnImage(img, obj.camBoxes[cam.camNum])\n",
    "        return img\n",
    "        \n",
    "    def showCameras(self):\n",
    "        f, ax = plt.subplots(1, len(cameras), figsize=(20,20))\n",
    "        for a, cam in zip(ax, cameras.values()):\n",
    "            a.imshow(self.drawObjectsOnCam(cam, cam.drawActiveZone(cam.imageBuffer[0])))\n",
    "            a.set_title(f\"Cam{cam.camNum}\")\n",
    "        plt.show()\n",
    "    \n",
    "    def showCamsUnwarped(self, cams=None):\n",
    "        cams = cams if cams is not None else list(cameras.values())\n",
    "        f, ax = plt.subplots(1, len(cams), figsize=(10, 10))\n",
    "        altogether = None\n",
    "        for axes, cam in zip(ax, cams):\n",
    "            warp = cv2.warpPerspective(cam.cropToActiveZone(cam.mostRecentFrame), cam.M, (1000, 1000))\n",
    "            altogether = cv2.addWeighted(altogether, 0.5, warp, 0.5, 0) if altogether is not None else warp\n",
    "            axes.imshow(warp)\n",
    "            axes.set_title(f\"Cam{cam.camNum}\")\n",
    "        plt.show()\n",
    "        f, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "        plt.imshow(altogether)\n",
    "        plt.show()\n",
    "        \n",
    "    def showCameraDelta(self, initial=1, final=0):\n",
    "        camImages = []\n",
    "        for cam in cameras.values():\n",
    "            changes = cam.changeBetween(cam.imageBuffer[initial], cam.imageBuffer[final])\n",
    "            camImages.append(cam.drawActiveZone(cam.drawBoxesOnImage(cam.imageBuffer[final], changes)))\n",
    "        f, ax = plt.subplots(1, len(cameras), figsize=(20, 20))\n",
    "        for a, cam, ci in zip(ax, cameras.values(), camImages):\n",
    "            a.imshow(ci)\n",
    "            a.set_title(f\"Cam{cam.camNum}\")\n",
    "        plt.show()\n",
    "    \n",
    "    def calibrate(self, calibrationBoxRealCoordinates={0: [500 + (110 / 5), 500 - (160 / 5)], 2: [500 + (110 / 5), 500 - (160 / 5)], 4: [500, 500]}):\n",
    "        self.capture()\n",
    "        decodes = cc.scanCamsForCalibrationBoxes()\n",
    "        for camNum, (decodes, numDecodes) in decodes.items():\n",
    "            if camNum not in calibrationBoxRealCoordinates:\n",
    "                continue\n",
    "                \n",
    "            cam = cameras[camNum]\n",
    "            cam.calibrationBox(CalibrationBox(dec.polygon, decodes[0].rect, dec.orientation, calibrationBoxRealCoordinates[camNum]))\n",
    "    \n",
    "    def debugCapture(self):\n",
    "        captures = self.capture()\n",
    "        print({cam: [d for d in camCap[1]] for cam, camCap in captures.items()})\n",
    "        self.showCameraDelta()\n",
    "        return captures\n",
    "    \n",
    "    def saveState(self):\n",
    "        state = {\n",
    "            camNum: {\n",
    "                \"az\": json.dumps(cam.activeZone.tolist()),\n",
    "                \"mw\": cam.minimumWidth,\n",
    "                \"m\": json.dumps(cam.M.tolist()) if cam.M is not None else None,\n",
    "                \"mct\": cam.MCalibratedTo if cam.M is not None else None}\n",
    "            for camNum, cam in cameras.items()}\n",
    "        state[\"objs\"] = {name: capObj.camBoxes\n",
    "                         for name, capObj in self.captureObjects.items()}\n",
    "        with open(\"observerState.json\", \"w\") as f:\n",
    "            f.write(json.dumps(state, indent=2))\n",
    "            \n",
    "    def recoverState(self):\n",
    "        with open(\"observerState.json\", \"r\") as f:\n",
    "            state = json.loads(f.read())\n",
    "        for camNum, camDef in state.items():\n",
    "            if str(camNum) == \"objs\":\n",
    "                cc.captureObjects = {name: CaptureObject(name, {\n",
    "                                        int(camNum): boxes for camNum, boxes in camBox.items()})\n",
    "                                     for name, camBox in camDef.items()}\n",
    "            else:\n",
    "                cameras[int(camNum)].activeZone = np.float32(json.loads(camDef['az']))\n",
    "                cameras[int(camNum)].minimumWidth = float(camDef['mw'])\n",
    "                cameras[int(camNum)].M = None if camDef['m'] is None else np.float32(json.loads(camDef['m']))\n",
    "                cameras[int(camNum)].MCalibratedTo = camDef.get('mct', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16e5a3b6-10c5-490d-84ba-17ab75507356",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@2.718] global cap_v4l.cpp:982 open VIDEOIO(V4L2:/dev/video1): can't open camera by index\n",
      "[ERROR:0@3.003] global obsensor_uvc_stream_channel.cpp:156 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@3.492] global cap_v4l.cpp:982 open VIDEOIO(V4L2:/dev/video3): can't open camera by index\n",
      "[ERROR:0@3.501] global obsensor_uvc_stream_channel.cpp:156 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@5.428] global cap_v4l.cpp:982 open VIDEOIO(V4L2:/dev/video5): can't open camera by index\n",
      "[ERROR:0@5.437] global obsensor_uvc_stream_channel.cpp:156 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@5.438] global cap_v4l.cpp:982 open VIDEOIO(V4L2:/dev/video6): can't open camera by index\n",
      "[ERROR:0@5.447] global obsensor_uvc_stream_channel.cpp:156 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@5.447] global cap_v4l.cpp:982 open VIDEOIO(V4L2:/dev/video7): can't open camera by index\n",
      "[ERROR:0@5.457] global obsensor_uvc_stream_channel.cpp:156 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@5.458] global cap_v4l.cpp:982 open VIDEOIO(V4L2:/dev/video8): can't open camera by index\n",
      "[ERROR:0@5.467] global obsensor_uvc_stream_channel.cpp:156 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@5.468] global cap_v4l.cpp:982 open VIDEOIO(V4L2:/dev/video9): can't open camera by index\n",
      "[ERROR:0@5.479] global obsensor_uvc_stream_channel.cpp:156 getStreamChannelGroup Camera index out of range\n"
     ]
    }
   ],
   "source": [
    "cameras = {camNum: Camera(camNum=camNum, activeZone=[(0, 0), (0, 1920), (2560, 1920), (2560, 0)]) for camNum in identify_usb_cameras()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2328f428-b048-4c6a-89c6-6dc1ce0282c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cc = CaptureConfiguration(__name__, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "199f7af5-3d65-43c0-80fe-e6686807070f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cc.recoverState()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
